{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d83fc8c3-6a0f-4d02-a7c8-7abe0afac540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 1 :\n",
    "# Anova (Analysis of variance)\n",
    "# Assumptions of anova\n",
    "# 1. Normality of sampling  distributions of Means\n",
    "#     the distribution of sample mean  is normally distributed\n",
    "# 2 . Absence of outliers\n",
    "#      outlying score need to be removed from the dataset \n",
    "# 3. Homogenity of variance\n",
    "#    each one if the population has some variance \n",
    "#    population variance in different levels of each independent variables are equal \n",
    "# 4 . samples are independent and random\n",
    "\n",
    "# If these assumptions are violated then annova results may get impacted\n",
    "# for example : \n",
    "# 1. Non-independence: Violations can occur when observations within groups are not independent. \n",
    "#    For example, in a study where the same participants are measured under different conditions or at different time points, \n",
    "#    violating the assumption of independence.\n",
    "\n",
    "# 2. Non-normality: Violations can occur when the data are not normally distributed within groups. \n",
    "#    For instance, if the data are heavily skewed or have a non-normal shape, the assumption of normality is violated.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47bc4931-81bb-4ac9-ab74-c57aebfcce90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 2 :\n",
    "# TYPES OF ANOVA ans situations they should be used\n",
    "# 1.one way anova : one factor with atleast two levels , these levels are independent\n",
    "#    eg : doctor wants to test new medication to decrease headache\n",
    "#        medication ----->Factor\n",
    "#         levels------->[10mg , 20mg , 30mg]\n",
    "\n",
    "# 2.repeated anova  : one factor with atleast 2 levels , but these levels are dependent \n",
    "#     eg: person is going for running everyday\n",
    "#         Factor----->running\n",
    "#         levels ------> day1 8km , day2 5km , day3 7km  (same person data)\n",
    "\n",
    "# 3.Factorial anova : Two or more factors each of which with atleast two levels . levels can be either independent and dependent\n",
    "#        Factor 1-----> running\n",
    "#        Factor 2 -----> gender (male , female)\n",
    "#        levels ------> how much kms they each day "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8ed4709-29a7-40b1-a20e-caac809f0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 3 :\n",
    "# \" partioning of variance \"\n",
    "# dividing the variance  with respect to groups associated\n",
    "# variation within the group and variation bteween the groups\n",
    "\n",
    "# Between-group variance:It measures the differences between the means of different groups in the study.\n",
    "# Within-group variance: It measures the differences between individual observations within the same group\n",
    "\n",
    "# partitioning of variance helps in interpreting the F-statistic and p-value obtained from ANOVA. \n",
    "# The F-statistic, calculated as the ratio of between-group variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d18c628d-54a8-40c3-b3c8-72898060f31c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 261.0769230769231\n",
      "SSE: 290.4429733727811\n",
      "SSR: -29.36605029585803\n",
      "F-value: 40.722753603664266\n",
      "p-value: 1.5638249382877062e-05\n"
     ]
    }
   ],
   "source": [
    "# ANS 4:\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "group1 = [10, 12, 15, 11, 13]\n",
    "group2 = [8, 7, 6, 9]\n",
    "group3 = [18, 20, 16, 19]\n",
    "\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "group_means = [np.mean(group1), np.mean(group2), np.mean(group3)]\n",
    "\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "sst = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "sse = np.sum((group_means - overall_mean) ** 2) * len(group1)\n",
    "\n",
    "ssr = sst - sse\n",
    "\n",
    "f_value, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "584cb87c-fc7f-4510-aeac-03fbc24d0f49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of Factor1: 366.8760683760686\n",
      "Main effect of Factor2: nan\n",
      "Interaction effect: 98.1777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1900: RuntimeWarning: invalid value encountered in divide\n",
      "  F /= J\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "# ANS 5 :\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "group1 = [10, 12, 15, 11, 13]\n",
    "group2 = [8, 7, 6, 9]\n",
    "group3 = [18, 20, 16, 19]\n",
    "\n",
    "\n",
    "data = group1 + group2 + group3\n",
    "factor1 = ['A'] * len(group1) + ['B'] * len(group2) + ['C'] * len(group3)\n",
    "factor2 = ['X'] * len(group1) + ['Y'] * len(group2) + ['X'] * len(group3)\n",
    "\n",
    "df = pd.DataFrame({'Data': data, 'Factor1': factor1, 'Factor2': factor2})\n",
    "\n",
    "\n",
    "model = ols('Data ~ Factor1 + Factor2 + Factor1:Factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "\n",
    "main_effect_factor1 = anova_table.loc['Factor1', 'sum_sq']\n",
    "main_effect_factor2 = anova_table.loc['Factor2', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['Factor1:Factor2', 'sum_sq']\n",
    "\n",
    "\n",
    "print(\"Main effect of Factor1:\", main_effect_factor1)\n",
    "print(\"Main effect of Factor2:\", main_effect_factor2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbdaa9f1-7a50-49b6-a901-d004b4314845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 6 :\n",
    "# F-statistic of 5.23 and a p-value of 0.02, we can conclude that there are significant differences between the groups being compared.\n",
    "# The F-statistic of 5.23 indicates that there is a significant amount of variability in the data that can be attributed to the differences between the groups\n",
    "# obtained p-value of 0.02 is less than the commonly used significance level of 0.05. \n",
    "# Therefore, we can conclude that there are statistically significant differences between the groups being compared in the study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7da806-5ab0-45ca-b6e6-cf47ca5adeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 7 :\n",
    "# HANDLING MISSING DATA\n",
    "# Complete Case Analysis (Listwise Deletion): In this approach, cases with missing data are entirely excluded from the analysis\n",
    "# Pairwise Deletion:It includes all cases with at least one complete observation in the analysis.\n",
    "# Mean Substitution: In this method, missing values are replaced with the mean value of the available data for that variable\n",
    "\n",
    "# cosequences\n",
    "# The consequences of using different methods to handle missing data include potential bias, \n",
    "# loss of statistical power, and incorrect conclusions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7634598e-3af2-48e6-9c52-9644c86364ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANS 8 :\n",
    "# POST HOC TESTS\n",
    "# 1 .Tukey's Honestly Significant Difference (HSD)\n",
    "# 2. Bonferroni correction:\n",
    "# 3 . Dunnett's test\n",
    "# 4. Scheffe's test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc5905bd-a3ed-4c89-b9c8-9cb8a273f774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SST: 76.4167441860465\n",
      "SSE: 0.5436505292436066\n",
      "SSR: 75.8730936568029\n",
      "F-value: 0.14875507760639367\n",
      "p-value: 0.8622546764644173\n"
     ]
    }
   ],
   "source": [
    "# ANS 9 :\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "# Example data\n",
    "# weight loss\n",
    "group1 = [3,2.5,3,1,5,3,4,2,2,3.4,2.5,4.3,2.7,1.4]\n",
    "group2 = [2,3,4,1,5,6,3,4,5,2,1.2,3.4,1.5,1.4,4.3]\n",
    "group3 = [1,2,3,4,5,1,2,3,4,5,2.4,3.2,4.5,1.3]\n",
    "\n",
    "data = np.concatenate([group1, group2, group3])\n",
    "\n",
    "group_means = [np.mean(group1), np.mean(group2), np.mean(group3)]\n",
    "\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "sst = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "sse = np.sum((group_means - overall_mean) ** 2) * len(group1)\n",
    "\n",
    "ssr = sst - sse\n",
    "\n",
    "f_value, p_value = stats.f_oneway(group1, group2, group3)\n",
    "\n",
    "\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b3a338a-3b18-4761-b111-906e9f0563cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main effect of Factor1: 0.015951426280215668\n",
      "Main effect of Factor2: nan\n",
      "Interaction effect: 1.1123940886699384\n",
      "SST: 2255.9555555555557\n",
      "SSE: 305.06000000000006\n",
      "SSR: 1950.8955555555558\n",
      "F-value: 10.867903970452446\n",
      "p-value: 6.12181228011506e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 1, but rank is 0\n",
      "  warnings.warn('covariance of constraints does not have full '\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1900: RuntimeWarning: invalid value encountered in divide\n",
      "  F /= J\n",
      "/opt/conda/lib/python3.10/site-packages/statsmodels/base/model.py:1871: ValueWarning: covariance of constraints does not have full rank. The number of constraints is 2, but rank is 1\n",
      "  warnings.warn('covariance of constraints does not have full '\n"
     ]
    }
   ],
   "source": [
    "# ANS 10:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "PROGRAM_A = np.random.randint(0,20,30)\n",
    "PROGRAM_B = np.random.randint(0,10,30)\n",
    "PROGRAM_C = np.random.randint(0,15,30)\n",
    "\n",
    "\n",
    "data = group1 + group2 + group3\n",
    "factor1 = ['A'] * len(group1) + ['B'] * len(group2) + ['C'] * len(group3)\n",
    "factor2 = ['X'] * len(group1) + ['Y'] * len(group2) + ['X'] * len(group3)\n",
    "\n",
    "df = pd.DataFrame({'Data': data, 'Factor1': factor1, 'Factor2': factor2})\n",
    "\n",
    "\n",
    "model = ols('Data ~ Factor1 + Factor2 + Factor1:Factor2', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "\n",
    "main_effect_factor1 = anova_table.loc['Factor1', 'sum_sq']\n",
    "main_effect_factor2 = anova_table.loc['Factor2', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['Factor1:Factor2', 'sum_sq']\n",
    "\n",
    "\n",
    "print(\"Main effect of Factor1:\", main_effect_factor1)\n",
    "print(\"Main effect of Factor2:\", main_effect_factor2)\n",
    "print(\"Interaction effect:\", interaction_effect)\n",
    "\n",
    "\n",
    "data = np.concatenate([PROGRAM_A,PROGRAM_B,PROGRAM_C])\n",
    "\n",
    "group_means = [np.mean(PROGRAM_A), np.mean(PROGRAM_B), np.mean(PROGRAM_B)]\n",
    "\n",
    "overall_mean = np.mean(data)\n",
    "\n",
    "sst = np.sum((data - overall_mean) ** 2)\n",
    "\n",
    "sse = np.sum((group_means - overall_mean) ** 2) * len(group1)\n",
    "\n",
    "ssr = sst - sse\n",
    "\n",
    "f_value, p_value = stats.f_oneway(PROGRAM_A,PROGRAM_B,PROGRAM_C)\n",
    "\n",
    "\n",
    "print(\"SST:\", sst)\n",
    "print(\"SSE:\", sse)\n",
    "print(\"SSR:\", ssr)\n",
    "print(\"F-value:\", f_value)\n",
    "print(\"p-value:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "603cbea0-3ec0-42ae-b173-d7e4c075658c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " t_statistic  -0.26723422323593155\n",
      " p_value  0.7895669692300302\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "data has 100 elements and groups has 200",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(control_scores \u001b[38;5;241m+\u001b[39m experimental_scores)\n\u001b[1;32m     15\u001b[0m groups \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mControl\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(control_scores) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExperimental\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(experimental_scores)\n\u001b[0;32m---> 17\u001b[0m posthoc \u001b[38;5;241m=\u001b[39m \u001b[43mpairwise_tukeyhsd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(posthoc)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/statsmodels/stats/multicomp.py:44\u001b[0m, in \u001b[0;36mpairwise_tukeyhsd\u001b[0;34m(endog, groups, alpha)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpairwise_tukeyhsd\u001b[39m(endog, groups, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.05\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m    Calculate all pairwise comparisons with TukeyHSD confidence intervals\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m    statsmodels.sandbox.stats.multicomp.TukeyHSDResults\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMultiComparison\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendog\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtukeyhsd(alpha\u001b[38;5;241m=\u001b[39malpha)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/statsmodels/sandbox/stats/multicomp.py:811\u001b[0m, in \u001b[0;36mMultiComparison.__init__\u001b[0;34m(self, data, groups, group_order)\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data, groups, group_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    810\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(groups):\n\u001b[0;32m--> 811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata has \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m elements and groups has \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(data), \u001b[38;5;28mlen\u001b[39m(groups)))\n\u001b[1;32m    812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data)\n\u001b[1;32m    813\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups \u001b[38;5;241m=\u001b[39m groups \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(groups)\n",
      "\u001b[0;31mValueError\u001b[0m: data has 100 elements and groups has 200"
     ]
    }
   ],
   "source": [
    "# ANS 11:\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "control_scores = np.random.randint(70,100,100) \n",
    "experimental_scores =np.random.randint(70,100,100)  \n",
    "\n",
    "t_statistic, p_value = stats.ttest_ind(control_scores, experimental_scores)\n",
    "print(\" t_statistic \" , t_statistic)\n",
    "print(\" p_value \" , p_value )\n",
    "\n",
    "data = np.array(control_scores + experimental_scores)\n",
    "groups = ['Control'] * len(control_scores) + ['Experimental'] * len(experimental_scores)\n",
    "\n",
    "posthoc = pairwise_tukeyhsd(data, groups)\n",
    "print(posthoc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fd666f2-25e9-4a44-b71c-8d34a9ca7da4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m STORE_B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m2000\u001b[39m,\u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m      7\u001b[0m STORE_C \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1000\u001b[39m,\u001b[38;5;241m2000\u001b[39m,\u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m df\u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m31\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mStore\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mB\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSales\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSTORE_A\u001b[49m\u001b[43m,\u001b[49m\u001b[43mSTORE_B\u001b[49m\u001b[43m,\u001b[49m\u001b[43mSTORE_C\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m model \u001b[38;5;241m=\u001b[39m AnovaRM(data\u001b[38;5;241m=\u001b[39mdf , depvar\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m , subject\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDay\u001b[39m\u001b[38;5;124m'\u001b[39m , within\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     15\u001b[0m results \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "# ANS 12:\n",
    "import pandas as pd\n",
    "from statsmodels.stats.anova import AnovaRM\n",
    "\n",
    "STORE_A = np.random.randint(1000,2000,30)\n",
    "STORE_B = np.random.randint(1000,2000,30)\n",
    "STORE_C = np.random.randint(1000,2000,30)\n",
    "\n",
    "df=pd.DataFrame({ 'Day': np.arange(1, 31),\n",
    "    'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "    'Sales': np.concatenate([STORE_A,STORE_B,STORE_C])\n",
    "})\n",
    "   \n",
    "model = AnovaRM(data=df , depvar='Sales' , subject='Day' , within=['Store'])\n",
    "results = model.fit()\n",
    "\n",
    "print(results.anova_table)\n",
    "\n",
    "posthoc = pairwise_tukeyhsd(df['Sales'], df['Store'], alpha=0.05)\n",
    "print(\"Post-hoc Test Results:\" , posthoc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786ea65-b414-459c-86f9-970280049195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
